{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2018 Semester 1\n",
    "-----\n",
    "## Project 1: What is labelled data worth to Naive Bayes?\n",
    "-----\n",
    "###### Student Name(s): HONGFEI YANG (783661)\n",
    "###### Python version: 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you may use for your Project 1 submission. (You are not required to use it; in particular, there is no need to use iPython if you do not like it.)\n",
    "\n",
    "Marking will be applied on the seven functions that are defined in this notebook, and to your responses to the questions at the end of this notebook.\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "import math\n",
    "#lstOfCSV = [\"breast-cancer.csv\", \"car.csv\", \"hypothyroid.csv\", \"mushroom.csv\"]\n",
    "lstOfCSV = ['train_top10.csv', 'dev_top10.csv', 'test_top10.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should open a data file in csv, and transform it into a usable format \n",
    "def preprocess(csv_file_name):\n",
    "    \"\"\"\n",
    "    preprocess the training dataset by droping all instances with '?' inside\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_file_name, header=None)\n",
    "    df = df.replace('?', np.NaN)\n",
    "    df.dropna(inplace=True);\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocessTestData(csv_file_name):\n",
    "    \"\"\"\n",
    "    preprocess test dataset by just reading it as a DataFrame\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_file_name, header=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should build a supervised NB model\n",
    "def train_supervised(df):\n",
    "    \"\"\"\n",
    "    return a trained NB supervised classifier.\n",
    "    \n",
    "    the classifier is a list of classes, in each class it has a list of dictionaries whose order\n",
    "    corresponds to the order of attributes of the traing data , each dictionary has this attribute's\n",
    "    values and their corresponding frequencies\n",
    "    \"\"\"\n",
    "    \n",
    "    def buildFreqDict(X, index):\n",
    "        \"\"\"\n",
    "        return frequencies of the values of this attribute, which is at 'index' position.\n",
    "        X is the data part of the training dataset\n",
    "        \"\"\"\n",
    "        attrFreqDict = {}\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            key = X[i][index]\n",
    "            if key != \"?\":\n",
    "                if key not in attrFreqDict:\n",
    "                    attrFreqDict[key] = 0\n",
    "                attrFreqDict[key] += 1\n",
    "\n",
    "        return attrFreqDict\n",
    "\n",
    "    def seperateByClass(df):\n",
    "        \"\"\"\n",
    "        return a dictionary with its key being each class, value being a list of attributes which have thier own\n",
    "        values dictionaries\n",
    "        \"\"\"\n",
    "        values = df.values\n",
    "        class_index = len(df.columns) - 1\n",
    "        \n",
    "        # seperate the dataset by data and groud truth\n",
    "        X = values[:,:class_index]\n",
    "        y = values[:, class_index]\n",
    "        \n",
    "        classDict = {}\n",
    "        for i in range(len(values)):\n",
    "            key = y[i]\n",
    "            val = X[i]\n",
    "            if key not in classDict:\n",
    "                classDict[key] = []\n",
    "            classDict[key].append(val)\n",
    "        return classDict\n",
    "\n",
    "    def buildClassiferDict(df):\n",
    "        \"\"\"\n",
    "        return the final classsifier by combining all the data structures we have\n",
    "        \"\"\"\n",
    "        \n",
    "        numClass = len(df.columns) - 1\n",
    "        \n",
    "        classifierDict = {}\n",
    "        \n",
    "        classDict = seperateByClass(df)\n",
    "        for y, X in classDict.items():\n",
    "            classifierDict[y] = []\n",
    "            for i in range(numClass):\n",
    "                attrFreqDict = buildFreqDict(X, i)\n",
    "                classifierDict[y].append(attrFreqDict)\n",
    "            \n",
    "            # we need to put the number of instances of this class for later use,\n",
    "            # so we put it at the end of each class\n",
    "            classifierDict[y].append(len(X))\n",
    "        return classifierDict\n",
    "    \n",
    "    return buildClassiferDict(df)\n",
    "\n",
    "#classifier = train_supervised(preprocess(\"breast-cancer.csv\"))\n",
    "#classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '14-16',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '14-16',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26',\n",
       " '24-26']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function should predict the class for a set of instances, based on a trained model \n",
    "def predict_supervised(classifier, testInstances, K=1):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for testInstanceIndex in range(len(testInstances)):\n",
    "        \n",
    "        testInstance = testInstances.iloc[testInstanceIndex, :]\n",
    "        currScore = None\n",
    "        outcome = None\n",
    "\n",
    "        # the total number of instances we have is calculated by adding each class's number,\n",
    "        # which is recorded at the end of the list of each class\n",
    "        totalInstanceCount = sum([val[len(val) - 1] for val in classifier.values()])\n",
    "\n",
    "        # calculate the probablity for each class to find the max score so we can determine what class it is\n",
    "        for predictedClass, attributeFreqLst in classifier.items():\n",
    "\n",
    "            # number of current class instances\n",
    "            totalInstanceInClass = attributeFreqLst[len(attributeFreqLst) - 1]\n",
    "\n",
    "\n",
    "            # beacause we are doing a lot of floating point multiplications that may affect accuracy,\n",
    "            # so we make these operations more accurate by having a single division and many interger\n",
    "            # multiplications\n",
    "            posteriorProbNumerator = 1\n",
    "            posteriorProbDenominator = 1\n",
    "\n",
    "            # iterate through each attribute to calculate probabilities\n",
    "            for i in range(len(testInstance)):\n",
    "                #print(len(testInstance))\n",
    "                # only care about fields with no missing data when predicting\n",
    "                if testInstance[i] != '?':\n",
    "\n",
    "                    # getting the total number of attribute values for this attribute, which is the |V| in the\n",
    "                    # denominator of Laplace smoothing\n",
    "                    lstOfAttributeExpr = set([item for sublst in [list(attriFreqLst[i].keys()) for attriFreqLst in classifier.values()] for item in sublst])\n",
    "                    v = len(lstOfAttributeExpr)\n",
    "\n",
    "                    # get the numerator & demoninator of each posterior probability and multiply them together respectively\n",
    "                    # add one to each attribute value for Laplace smoothing\n",
    "                    posteriorProbNumerator *= (attributeFreqLst[i].get(testInstance[i], 0) + K)\n",
    "                    posteriorProbDenominator *= (totalInstanceInClass + v*K)\n",
    "\n",
    "            # finally muliply by the prior probabilities and divde numerator and denominator\n",
    "            probability = (totalInstanceInClass * posteriorProbNumerator) / (totalInstanceCount * posteriorProbDenominator)\n",
    "\n",
    "            if currScore is None:\n",
    "                # initiallise score here\n",
    "                currScore = probability\n",
    "                outcome = predictedClass\n",
    "            elif probability > currScore:\n",
    "                # remember the largest probability to determine the final classification\n",
    "                currScore = probability\n",
    "                outcome = predictedClass\n",
    "        \n",
    "        result.append(outcome)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "#df = preprocess(\"breast-cancer.csv\")\n",
    "\n",
    "#testInstances = df.iloc[:1, :len(df.columns) - 1]\n",
    "#predict_supervised(train_supervised(df), testInstances)\n",
    "\n",
    "train_df = preprocess(\"train_top10.csv\")\n",
    "test_df = preprocess(\"dev_top10.csv\")\n",
    "test_df = test_df.iloc[:100,:len(test_df.columns)-1]\n",
    "predict_supervised(train_supervised(train_df), test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     w/o CrossValidation  w/ CrossValidation  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0dce16a9fa17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mget_metrics_supervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-0dce16a9fa17>\u001b[0m in \u001b[0;36mget_metrics_supervised\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m#test_df = preprocessTestData(oneFile)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_supervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{:<20} {:<20.5f} {:<20.5f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moneFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_supervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_validate_supervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-0dce16a9fa17>\u001b[0m in \u001b[0;36mevaluate_supervised\u001b[0;34m(classifier, df)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtestInstances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_supervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestInstances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-827dc9221a3c>\u001b[0m in \u001b[0;36mpredict_supervised\u001b[0;34m(classifier, testInstances, K)\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0;31m# getting the total number of attribute values for this attribute, which is the |V| in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0;31m# denominator of Laplace smoothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                     \u001b[0mlstOfAttributeExpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublst\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattriFreqLst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattriFreqLst\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstOfAttributeExpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This function should evaluate a set of predictions, in a supervised context \n",
    "def evaluate_supervised(classifier, df):\n",
    "    \"\"\"\n",
    "    evaluate supervised classifier by testing it again a set of data 'df'\n",
    "    the accuracy is calculated by the number of correct prediction, divided by the\n",
    "    total number of test instances\n",
    "    \"\"\"\n",
    "    correctCount = 0\n",
    "    totalCount = 0\n",
    "   \n",
    "            \n",
    "    testInstances = df.iloc[:, :len(df.columns) - 1]\n",
    "    result = predict_supervised(classifier, testInstances)\n",
    "    answer = list(df.iloc[:, len(df.columns) - 1])\n",
    "\n",
    "    for i in range(len(answer)):\n",
    "        if result[i] == answer[i]:\n",
    "            correctCount += 1\n",
    "        totalCount += 1\n",
    "        \n",
    "    return correctCount / totalCount\n",
    "\n",
    "\n",
    "def cross_validate_supervised(df, numPartition=10):\n",
    "    \"\"\"\n",
    "    cross validate a supervised classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    # shuffle the data first\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # determine the split side based on how many folds we want, default 10\n",
    "    splitSize = math.ceil(len(df) / numPartition)\n",
    "    \n",
    "    \n",
    "    startIndex = 0\n",
    "    endIndex = splitSize-1\n",
    "    accuracies = []\n",
    "    for i in range(numPartition):\n",
    "                \n",
    "        # split dataset into test data and training data\n",
    "        test_df = df.iloc[startIndex:endIndex, :]\n",
    "        train_df = df.drop(df.index[startIndex:endIndex])\n",
    "        \n",
    "        # cross validation using training data to train the classifier\n",
    "        # then use this to test against test data\n",
    "        classifier = train_supervised(train_df)\n",
    "        accuarcy = evaluate_supervised(classifier, test_df)\n",
    "        \n",
    "        accuracies.append(accuarcy)\n",
    "        \n",
    "        # adjust for next split\n",
    "        startIndex = endIndex+1\n",
    "        endIndex += splitSize-1\n",
    "        \n",
    "    \n",
    "    # return the average of accuracies \n",
    "    return sum(accuracies)/numPartition\n",
    "\n",
    "\n",
    "def get_metrics_supervised():\n",
    "    \"\"\"\n",
    "    print the metrics of unsupervised NB for all four files\n",
    "    \"\"\"\n",
    "    print(\"{:<20} {:<20} {:<20}\".format(\" \", \"w/o CrossValidation\", \"w/ CrossValidation\"))\n",
    "    for oneFile in lstOfCSV:\n",
    "        train_df = preprocessTestData(oneFile)\n",
    "        test_df = train_df\n",
    "        #test_df = preprocessTestData(oneFile)\n",
    "        classifier = train_supervised(train_df)\n",
    "        print(\"{:<20} {:<20.5f} {:<20.5f}\".format(oneFile, evaluate_supervised(classifier, test_df), cross_validate_supervised(train_df)))\n",
    "    return\n",
    "\n",
    "get_metrics_supervised()\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "breast-cancer.csv     0.76895  0.73903\n",
    "car.csv               0.87153  0.85623\n",
    "hypothyroid.csv       0.95146  0.95148\n",
    "mushroom.csv          0.97697  0.97425\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should build an unsupervised NB model \n",
    "def train_unsupervised(df, NUM_ITER=10):\n",
    "    \"\"\"\n",
    "    return a trained unsupervised classifier. number of iterations used to train is default to be 10\n",
    "    \"\"\"\n",
    "    values = df.values\n",
    "    \n",
    "    numAttribute = len(df.columns) - 1 # number of attributes\n",
    "    \n",
    "    # divide dataset into data and groud truth\n",
    "    X = values[:,:numAttribute]\n",
    "    y = values[:,numAttribute]\n",
    "    \n",
    "    numClass = len(set(y)) # number of classes\n",
    "    \n",
    "    # calibrate a classifier using a matrix of probabilities\n",
    "    def buildNewClassifier(X, labelProbMatrix, numClass=numClass, numAttribute=numAttribute):\n",
    "        \n",
    "        # this classifier is a list of list of dictionaries, each dictioary contain the total probabilities\n",
    "        # a corresponding attribute value\n",
    "        newClassifier = []\n",
    "        \n",
    "        # each attribute has a list of dictionary \n",
    "        for attributeIndex in range(numAttribute):\n",
    "\n",
    "            attributeLabelProbDictList = []\n",
    "            \n",
    "            # for each label, get the total probabilities of each attribute value by looking through all\n",
    "            # instances\n",
    "            for labelIndex in range(numClass): \n",
    "\n",
    "                attributeDict = {}\n",
    "                \n",
    "                # look through all instances to update probabilities of each attribute values\n",
    "                for instanceIndex in range(len(X)):\n",
    "\n",
    "                    instance = X[instanceIndex]\n",
    "                    attributeExpression = instance[attributeIndex]\n",
    "                    \n",
    "                    if attributeExpression != \"?\":\n",
    "                        \n",
    "                        if attributeExpression not in attributeDict:\n",
    "                            attributeDict[attributeExpression] = 0\n",
    "\n",
    "                        # add this correspoinding probability from the label probability matrix\n",
    "                        attributeDict[attributeExpression] += labelProbMatrix[instanceIndex][labelIndex]\n",
    "\n",
    "                attributeLabelProbDictList.append(attributeDict)\n",
    "\n",
    "            newClassifier.append(attributeLabelProbDictList)\n",
    "                \n",
    "        return newClassifier\n",
    "\n",
    "    # use the newly trained classier to get the label probabilty distribution matrix \n",
    "    def getNewLabelProbMatrix(X, classifier, labelProbMatrix, numClass=numClass, numAttribute=numAttribute):\n",
    "        \n",
    "        \n",
    "        # this matrix has the same number of rows of the data, and its column number is the number of classes in this data\n",
    "        newLabelProbMatrix = []\n",
    "\n",
    "        for instanceIndex in range(len(X)):\n",
    "\n",
    "            instance = X[instanceIndex]\n",
    "\n",
    "            newLabelProbLst = []\n",
    "            \n",
    "            # process one column each time\n",
    "            for labelIndex in range(numClass):\n",
    "                \n",
    "                # total probability of this label\n",
    "                labelProbSum = sum([prob[labelIndex] for prob in labelProbMatrix])\n",
    "\n",
    "                # prior probability\n",
    "                newLabelProb = labelProbSum / len(X)\n",
    "\n",
    "                # under this label, check each attribute\n",
    "                for attributeIndex in range(numAttribute):\n",
    "\n",
    "                    # attibute value of this instance\n",
    "                    attributeExpression = instance[attributeIndex]\n",
    "\n",
    "                    if attributeExpression != \"?\":\n",
    "                        # get the posterior probability of this attribute of this instance:\n",
    "                        #\n",
    "                        # get the probabilities of this attribute of this label of this attribute value,\n",
    "                        # divided by total probability of this label\n",
    "                        attributePosteriorProb = classifier[attributeIndex][labelIndex].get(attributeExpression, 0) / labelProbSum\n",
    "\n",
    "                        # muliply each conditional probability together\n",
    "                        newLabelProb *= attributePosteriorProb\n",
    "\n",
    "                newLabelProbLst.append(newLabelProb)\n",
    "            \n",
    "            # normalise\n",
    "            newLabelProbLst = [i/sum(newLabelProbLst) for i in newLabelProbLst]\n",
    "\n",
    "            newLabelProbMatrix.append(newLabelProbLst)\n",
    "\n",
    "        return newLabelProbMatrix\n",
    "\n",
    "    def convertToUnaryMatrix(labelProbMatrix):\n",
    "        \"\"\"\n",
    "        convert n X numClass matrix to n X 1 matrix\n",
    "        \"\"\"\n",
    "        \n",
    "        unaryMatrix = []\n",
    "        for row in labelProbMatrix:\n",
    "            currMax = row[0]\n",
    "            currMaxIndex = 0\n",
    "            for i in range(1, len(row)):\n",
    "                item = row[i]\n",
    "                if item > currMax:\n",
    "                    currMax = item\n",
    "                    currMaxIndex = i\n",
    "            # use the max probality's index as class name\n",
    "            unaryMatrix.append(currMaxIndex)\n",
    "\n",
    "        return unaryMatrix\n",
    "\n",
    "    \n",
    "    def buildFinalClassifier(X, unaryMatrix):\n",
    "        \"\"\"\n",
    "        conbine our data with the newly formed unary matrix and\n",
    "        train this data to get our final classifier that can give\n",
    "        us a cluster number for a particular instance\n",
    "        \"\"\"\n",
    "        _X = pd.DataFrame(X)\n",
    "        _y = pd.DataFrame(unaryMatrix)\n",
    "\n",
    "        newDF = pd.concat([_X, _y], axis=1, ignore_index=True)\n",
    "\n",
    "        # train this as the same as supervised one\n",
    "        classifier = train_supervised(newDF)\n",
    "\n",
    "        return classifier\n",
    "    \n",
    "    \n",
    "    # Initiallise the label probability matrix, \n",
    "    # We use a non-uniform distribution (Dirichlet Distribution) here. Total probability for each\n",
    "    # row is 1\n",
    "    labelProbMatrix = np.random.dirichlet(np.ones(numClass), size=len(df))\n",
    "    \n",
    "    # Train this data for serveral iterations\n",
    "    i = NUM_ITER\n",
    "    while (i>0):\n",
    "        classifier = buildNewClassifier(X, labelProbMatrix)\n",
    "        labelProbMatrix = getNewLabelProbMatrix(X, classifier, labelProbMatrix)\n",
    "        i -= 1\n",
    "    \n",
    "    # and get our final classifier\n",
    "    unaryMatrix = convertToUnaryMatrix(labelProbMatrix)\n",
    "    finalClassifier = buildFinalClassifier(X, unaryMatrix)\n",
    "    \n",
    "    return finalClassifier\n",
    "\n",
    "#df = preprocessTestData(\"breast-cancer.csv\")\n",
    "#classifier = train_unsupervised(df)\n",
    "#classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getMostAccurateClassification(classifier, training_df):\n",
    "    \"\"\"\n",
    "    do swapping to get the most accurate classification for the data\n",
    "    \"\"\"    \n",
    "    values = training_df.values\n",
    "    \n",
    "    numAttribute = len(training_df.columns) - 1\n",
    "\n",
    "    X = values[:,:numAttribute]\n",
    "    y = values[:,numAttribute]\n",
    "    \n",
    "    numClass = len(set(y))\n",
    "\n",
    "    # set of classes\n",
    "    classification = list(set(y))\n",
    "\n",
    "    # do this for permuation because two or more clusters can be mapped to one class\n",
    "    classification *= numClass\n",
    "    \n",
    "    # list of different classification\n",
    "    possibleClassifications = list(permutations(classification, numClass))\n",
    "    \n",
    "    # get the unlabelled predictions\n",
    "    unlabeledPrediction = predict_supervised(classifier, training_df.iloc[:, :numAttribute])\n",
    "\n",
    "    # the calculate the most accurate labelling\n",
    "    highestAccuracy = 0\n",
    "    highestAccuracyClassification = None\n",
    "    for oneClassification in possibleClassifications:\n",
    "        \n",
    "        # get one type of labelling\n",
    "        predictionMapToClass = [oneClassification[unlabeledPrediction[i]] for i in range(len(unlabeledPrediction))]\n",
    "\n",
    "        # get its accuracy\n",
    "        accuracy = sum([1 if y[i] == predictionMapToClass[i] else 0 for i in range(len(unlabeledPrediction))]) / len(unlabeledPrediction)\n",
    "\n",
    "        # keep the highest one\n",
    "        if accuracy > highestAccuracy:\n",
    "            highestAccuracy = accuracy\n",
    "            highestAccuracyClassification = oneClassification\n",
    "\n",
    "    assert(highestAccuracyClassification != None)\n",
    "    \n",
    "    return highestAccuracyClassification\n",
    "\n",
    "\n",
    "# This function should predict the class distribution for a set of instances, based on a trained model\n",
    "def predict_unsupervised(classifier, testInstance, classification):\n",
    "    \n",
    "    # get the unlabel result first\n",
    "    unlabeledResult = predict_supervised(classifier, testInstance)\n",
    "    \n",
    "    # then use the most accurate classification we derived to label this result\n",
    "    labeledResult = [classification[r] for r in unlabeledResult ]\n",
    "\n",
    "    #return labeledResult\n",
    "    return unlabeledResult, labeledResult\n",
    "\n",
    "#df = preprocess(\"breast-cancer.csv\")\n",
    "#classifier = train_unsupervised(df)\n",
    "#classification = getMostAccurateClassification(classifier, df)\n",
    "#predict_unsupervised(classifier, df.iloc[:30, :len(df.columns)-1], classification)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should evaluate a set of predictions, in an unsupervised manner\n",
    "def evaluate_unsupervised(classifier, training_df, test_df):\n",
    "    \n",
    "    # ensure the list is not empty\n",
    "    assert(not test_df.empty)\n",
    "    \n",
    "    # get the most accurate classification for this dataset\n",
    "    classification = getMostAccurateClassification(classifier, training_df)\n",
    "    \n",
    "    correctCount = 0\n",
    "    totalCount = 0\n",
    "\n",
    "    answer = list(test_df.iloc[:, len(test_df.columns)-1])\n",
    "        \n",
    "    result, labeledResult = predict_unsupervised(classifier, test_df.iloc[:, :len(test_df.columns)-1], classification)\n",
    "\n",
    "    # check the accuracy based on this classification we got earlier\n",
    "    for i in range(len(answer)):\n",
    "        \n",
    "        if labeledResult[i] == answer[i]:\n",
    "            correctCount += 1\n",
    "        totalCount += 1\n",
    "    \n",
    "    accuarcy = correctCount / totalCount\n",
    "    \n",
    "    \n",
    "    # build a confusion matrix using the unlabled data\n",
    "    confusionDict = {}\n",
    "\n",
    "    for i in range(len(answer)):\n",
    "        \n",
    "        if answer[i] not in confusionDict:\n",
    "            confusionDict[answer[i]] = {}\n",
    "            \n",
    "        if result[i] not in confusionDict[answer[i]]:\n",
    "            confusionDict[answer[i]][result[i]] = 0\n",
    "            \n",
    "        confusionDict[answer[i]][result[i]] += 1\n",
    "\n",
    "        \n",
    "    return confusionDict, classification, accuarcy\n",
    "\n",
    "\n",
    "def cross_validate_unsupervised(df, numPartition=10):\n",
    "    \"\"\"\n",
    "    cross validate an unsupervised classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    # shuffle the data first\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # determine the split side based on how many folds we want, default 10\n",
    "    splitSize = math.ceil(len(df) / numPartition)\n",
    "    \n",
    "    \n",
    "    startIndex = 0\n",
    "    endIndex = splitSize-1\n",
    "    accuracies = []\n",
    "    for i in range(numPartition):\n",
    "        \n",
    "        # split dataset into test data and training data\n",
    "        test_df = df.iloc[startIndex:endIndex, :]\n",
    "        train_df = df.drop(df.index[startIndex:endIndex])\n",
    "        \n",
    "        # cross validation by using the training data to train the classifier\n",
    "        # then use test data to check the classifier performance\n",
    "        classifier = train_unsupervised(train_df)\n",
    "        confusionDict, classification, accuarcy = evaluate_unsupervised(classifier, train_df, test_df)\n",
    "        \n",
    "        accuracies.append(accuarcy)\n",
    "        \n",
    "        # adjust for next split\n",
    "        startIndex = endIndex+1\n",
    "        endIndex += splitSize-1\n",
    "        \n",
    "    \n",
    "    # return the average of accuracies \n",
    "    return sum(accuracies)/numPartition\n",
    "\n",
    "#df = preprocess(\"breast-cancer.csv\")\n",
    "#cross_validate_unsupervised(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                   cross validation\n",
    "breast-cancer.csv  0.7128205128205127\n",
    "          car.csv  0.7007683938528493\n",
    "  hypothyroid.csv  0.9521288971614703\n",
    "     mushroom.csv  0.7859947973747529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d6373c566354>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mprint_metrics_unsupervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-d6373c566354>\u001b[0m in \u001b[0;36mprint_metrics_unsupervised\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#test_df = preprocessTestData(oneFile)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_unsupervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mconfusionDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuarcy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_unsupervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-6830ea3ac59b>\u001b[0m in \u001b[0;36mtrain_unsupervised\u001b[0;34m(df, NUM_ITER)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildNewClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelProbMatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mlabelProbMatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetNewLabelProbMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelProbMatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-6830ea3ac59b>\u001b[0m in \u001b[0;36mgetNewLabelProbMatrix\u001b[0;34m(X, classifier, labelProbMatrix, numClass, numAttribute)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;31m# total probability of this label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mlabelProbSum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabelIndex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabelProbMatrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;31m# prior probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def print_metrics_unsupervised():\n",
    "    \"\"\"\n",
    "    print confusion matrix with other stats for all four datasets\n",
    "    \"\"\"\n",
    "    \n",
    "    for oneFile in lstOfCSV:\n",
    "        \n",
    "        # get stats first\n",
    "        training_df = preprocess(oneFile)\n",
    "        test_df = training_df\n",
    "        #test_df = preprocessTestData(oneFile)\n",
    "        classifier = train_unsupervised(training_df)\n",
    "        confusionDict, classification, accuarcy = evaluate_unsupervised(classifier, training_df, test_df)\n",
    "        \n",
    "        output = \"{:>20}\".format(oneFile)\n",
    "        for i in range(len(classification)):\n",
    "            output += \"{:>7}\".format(i)\n",
    "        output += \"{:>7}\".format(\"Total\")\n",
    "        print(output)\n",
    "        output = \"-\"*(20+7*(len(classification)+1))\n",
    "        print(output)\n",
    "        for (key, val) in confusionDict.items():\n",
    "            total = 0\n",
    "            output = \"\"\n",
    "            for i in range(len(classification)):\n",
    "                output += \"{:>7}\".format(val.get(i, 0))\n",
    "                total += val.get(i, 0)\n",
    "            output += \"{:>7}\".format(total)\n",
    "            print(\"{:>20}{}\".format(key, output))\n",
    "\n",
    "        output = \"{:>20}\".format(\"Total\")\n",
    "\n",
    "        totalTotal = 0\n",
    "        for i in range(len(classification)):\n",
    "            total = 0\n",
    "            for (k, v) in confusionDict.items():\n",
    "                total += v.get(i, 0)\n",
    "            output += \"{:>7}\".format(total)\n",
    "            totalTotal += total\n",
    "        output += \"{:>7}\".format(totalTotal)\n",
    "        print(output)\n",
    "        output = \"-\"*(20+7*(len(classification)+1))\n",
    "        print(output)\n",
    "        output = \"\"\n",
    "        for i in range(len(classification)):\n",
    "            output += \"{} -> {}    \".format(i, classification[i])\n",
    "        print(\"Most accurate classification is:\")\n",
    "        print(output)\n",
    "        print(\"Accuarcy:\", accuarcy)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "print_metrics_unsupervised()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Result: 10 Times\n",
    "\n",
    "    breast-cancer.csv      0      1  Total\n",
    "-----------------------------------------\n",
    "    recurrence-events     29     52     81\n",
    " no-recurrence-events     90    106    196\n",
    "                Total    119    158    277\n",
    "\n",
    "             car.csv      0      1      2      3  Total\n",
    "-------------------------------------------------------\n",
    "               unacc    392    217    258    343   1210\n",
    "                 acc     98     79     48    159    384\n",
    "               vgood     10     15     19     21     65\n",
    "                good      5     19     12     33     69\n",
    "               Total    505    330    337    556   1728\n",
    "\n",
    "     hypothyroid.csv      0      1  Total\n",
    "-----------------------------------------\n",
    "         hypothyroid    149      0    149\n",
    "            negative   2698    243   2941\n",
    "               Total   2847    243   3090\n",
    "\n",
    "        mushroom.csv      0      1  Total\n",
    "-----------------------------------------\n",
    "                   p   1332    824   2156\n",
    "                   e      0   3488   3488\n",
    "               Total   1332   4312   5644\n",
    "\n",
    "\n",
    "Result: 50 Times\n",
    "\n",
    "   breast-cancer.csv      0      1  Total\n",
    "-----------------------------------------\n",
    "   recurrence-events     41     40     81\n",
    "no-recurrence-events     35    161    196\n",
    "               Total     76    201    277\n",
    "\n",
    "             car.csv      0      1      2      3  Total\n",
    "-------------------------------------------------------\n",
    "               unacc    379    304    259    268   1210\n",
    "                 acc     37     73    126    148    384\n",
    "               vgood     16      3     23     23     65\n",
    "                good     10     13     21     25     69\n",
    "               Total    442    393    429    464   1728\n",
    "\n",
    "     hypothyroid.csv      0      1  Total\n",
    "-----------------------------------------\n",
    "         hypothyroid      0    149    149\n",
    "            negative    243   2698   2941\n",
    "               Total    243   2847   3090\n",
    "\n",
    "        mushroom.csv      0      1  Total\n",
    "-----------------------------------------\n",
    "                   p   1340    816   2156\n",
    "                   e     15   3473   3488\n",
    "               Total   1355   4289   5644\n",
    "               \n",
    "\n",
    "Results: 10 Times with noise\n",
    "\n",
    "   breast-cancer.csv      0      1  Total\n",
    "-----------------------------------------\n",
    "   recurrence-events     47     38     85\n",
    "no-recurrence-events     46    155    201\n",
    "               Total     93    193    286\n",
    "\n",
    "             car.csv      0      1      2      3  Total\n",
    "-------------------------------------------------------\n",
    "               unacc    477    185    239    309   1210\n",
    "                 acc    136    116     26    106    384\n",
    "               vgood     22      7     19     17     65\n",
    "                good     36     22      1     10     69\n",
    "               Total    671    330    285    442   1728\n",
    "\n",
    "     hypothyroid.csv      0      1  Total\n",
    "-----------------------------------------\n",
    "         hypothyroid      0    151    151\n",
    "            negative    248   2764   3012\n",
    "               Total    248   2915   3163\n",
    "\n",
    "        mushroom.csv      0      1  Total\n",
    "-----------------------------------------\n",
    "                   p   2188   1728   3916\n",
    "                   e   2277   1931   4208\n",
    "               Total   4465   3659   8124"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions (you may respond in a cell or cells below):\n",
    "\n",
    "1. Since we’re starting off with random guesses, it might be surprising that the unsupervised NB works at all. Explain what characteristics of the data cause it to work pretty well (say, within 10% Accuracy of the supervised NB) most of the time; also, explain why it utterly fails sometimes.\n",
    "2. When evaluating supervised NB across the four different datasets, you will observe some variation in effectiveness (e.g. Accuracy). Explain what causes this variation. Describe and explain any particularly suprising results.\n",
    "3. Evaluating the model on the same data that we use to train the model is considered to be a major mistake in Machine Learning. Implement a hold–out (hint: check out numpy.shuffle()) or cross–validation evaluation strategy. How does your estimate of Accuracy change, compared to testing on the training data? Explain why. (The result might surprise you!)\n",
    "4. Implement one of the advanced smoothing regimes (add-k, Good-Turing). Do you notice any variation in the predictions made by either the supervised or unsupervised NB classifiers? Explain why, or why not.\n",
    "5. The lecture suggests that deterministically labelling the instances in the initialisation phase of the unsupervised NB classifier “doesn’t work very well”. Confirm this for yourself, and then demonstrate why.\n",
    "6. Rather than evaluating the unsupervised NB classifier by assigning a class deterministically, instead calculate how far away the probabilistic estimate of the true class is from 1 (where we would be certain of the correct class), and take the average over the instances. Does this performance estimate change, as we alter the number of iterations in the method? Explain why.\n",
    "7. Explore what causes the unsupervised NB classifier to converge: what proportion of instances change their prediction from the random assignment, to the first iteration? From the first to the second? What is the latest iteration where you observe a prediction change? Make some conjecture(s) as to what is occurring here.\n",
    "\n",
    "Don't forget that groups of 1 student should respond to question (1), and one other question. Groups of 2 students should respond to question (1), and three other questions. Your responses should be about 100-200 words each."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " 1. Unsupervised NB works well when the training data has a strong bias, and the training data has only two instances. For instance, consider the \"hypothyroid.csv\" statistics below: If remove all instances with missing values as training data, there are only 149 'hypothyroid' case but there are 2941 cases of 'negative'. This cause the data to be strongly biased towards 'negative' because one can easily predict negative just because this data occurs much more often than hypothyroid. Therefore, although 'hypothyroid' looks like cluster 1,  cluster 1 has much more 'negative' cases so the classifier just puts everything as 'negative', which will yield the maximum accuracy, almost the same as supervised one. However, this classification is practically useless because rational people tend to find true positive in this kind of data.\n",
    "\n",
    "     hypothyroid.csv      0      1  Total\n",
    "-----------------------------------------\n",
    "         hypothyroid      0    149    149\n",
    "            negative    243   2698   2941\n",
    "               Total    243   2847   3090\n",
    "\n",
    "If the data only have two classes, the result tends to be 'polarised'. The probability of each label of the same instance will have one converge to 1 and the other one converges to 0. This will make clustering have a more definite boundary. If the nature of the classes is indeed less interdependent, then unsupervised NB tends to be a clustering algorithm and will produce similar results as the actual distribution, thus produces a high accuracy.\n",
    "\n",
    "Unsupervised NB fails when the initial distribution is not good (more uniform). For example in the case of \"mushroom.csv\", by picking different initial random probability for each label, the prediction after the first iteration tends to have an unpredictable accuracy, however, as the number of iterations goes on, the fluctuation of accuracy will be much smaller and the accuracy tends to stabilise as somewhere not far from the initial accuracy. This means that a bad selection of initial distribution will affect the accuracy of the classification\n",
    "\n",
    "It also fails when the number of classes is too many. For example, in \"car.csv\", there are four classes, unlike two classes, after several iterations, its probability distribution tends to converge to 1/4 rather than 1 or 0. This makes classification difficult because it is not very clear which label should pick, therefore, accuracy plummets from 0.87 to 0.7."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3. Cross validation implemented.\n",
    "                    \n",
    "Unsupervised       without cross validation  with cross validation\n",
    "--------------------------------------------------------------------\n",
    "breast-cancer.csv  0.7256317689530686        0.7128205128205127 \n",
    "          car.csv  0.7002314814814815        0.7007683938528493   \n",
    "  hypothyroid.csv  0.9517799352750809        0.9521288971614703 \n",
    "     mushroom.csv  0.7349397590361446        0.7859947973747529  \n",
    "\n",
    "\n",
    "Supervised         w/o CrossValidation       w/ CrossValidation  \n",
    "--------------------------------------------------------------------\n",
    "breast-cancer.csv  0.75175                   0.71958             \n",
    "car.csv            0.87153                   0.85037             \n",
    "hypothyroid.csv    0.95194                   0.95175             \n",
    "mushroom.csv       0.95667                   0.95451\n",
    "\n",
    "For unsupervised NB, cross validation result is very close to the result without cross validation except for 'mushroom.csv'. This may because that 'mushroom.csv' depends on initial distribution and its result fluctuates, so the average of 10-fold cross validation may vary. For the rest, since unsupervised NB already iterates many times so the result may have already converged, also the datasets are biased as they contain more instances than others, which makes their convergence faster. Therefore doing cross validation will get a result closer to the converged values for each dataset.\n",
    "\n",
    "For supervised NB, cross validation tends to have less accuracy than the result without cross validation. This is because that evaluating the model based on the training datasets often over-estimate accuracy. So cross validation reduces the variance and thus make evaluated accuracy more realistic."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5. Using 'mushroom.csv' run 50 times as an example:\n",
    "\n",
    "        mushroom.csv      0      1  Total\n",
    "-----------------------------------------\n",
    "                   p   1340    816   2156\n",
    "                   e     15   3473   3488\n",
    "               Total   1355   4289   5644\n",
    "\n",
    "If label cluster 0 with e and 1 with p initially, the resulting accuracy is (15 + 816) / 5644 = 0.147 which is very small. Actually, any cluster labels other than (0:p, 1:e) will get a non-optimal accuracy. Therefore we cannot gurantee which label should we pick initally. Also the classification of each instance will vary with each iterations, so it is very hard to determine what cluster or label does it belong to. We should only label the instances after serveral iterations so that the cluster group of each instance is almost fixed, then we can pick our desired classification by maximising its accuracy, which is (0:p, 1:2) with accuracy 0.853. This process is called 'swap' and is already implemented."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
